# app.py
import io
import re
import statistics
from dataclasses import dataclass
from typing import List, Tuple, Optional

import fitz  # PyMuPDF
import pandas as pd
import streamlit as st
from openpyxl import Workbook, load_workbook

# ===== –ü–ê–†–ê–ú–ï–¢–†–´, –º–æ–∂–Ω–æ —Ç—Ä–æ–≥–∞—Ç—å –ø—Ä–∏ —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–µ =====
Y_LINE_TOL_FACTOR   = 0.65   # —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–∫–ª–µ–π–∫–∏ —Å–ª–æ–≤ –≤ —Å—Ç—Ä–æ–∫–∏ –ø–æ Y (–æ—Ç —Å—Ä–µ–¥–Ω–µ–π –≤—ã—Å–æ—Ç—ã)
ORDER_X_TOL         = 42.0   # —Ä–∞–¥–∏—É—Å X –¥–ª—è ¬´–∫–æ–ª–æ–Ω–∫–∏ –∑–∞–∫–∞–∑–æ–≤¬ª
ORDER_NEAR_Y        = 30.0   # –µ—Å–ª–∏ –Ω–µ—Ç –º–∞—Ä–∫–µ—Ä–∞ ¬´–≤—ã—à–µ¬ª, –±–µ—Ä—ë–º –±–ª–∏–∂–∞–π—à–∏–π –≤ –æ–∫–Ω–µ ¬±30px
QTY_MAX_LOOK_LINES  = 2      # —Å–∫–æ–ª—å–∫–æ —Å–æ—Å–µ–¥–Ω–∏—Ö –ª–∏–Ω–∏–π —Å–≤–µ—Ä—Ö—É/—Å–Ω–∏–∑—É —Å–º–æ—Ç—Ä–µ—Ç—å, –µ—Å–ª–∏ –≤ —Å–≤–æ–µ–π –Ω–µ –Ω–∞—à–ª–∏
SUM_MAX_LOOK_LINES  = 2
# =========================================================

st.set_page_config(page_title="Waybill Maker", page_icon="üì¶", layout="wide")
st.title("üì¶ Waybill Maker")

# ------------ –†–µ–≥—É–ª—è—Ä–∫–∏ -------------
RE_MPN   = re.compile(r"\b(8\d{10})\b")                               # 11 —Ü–∏—Ñ—Ä, –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 8
RE_MONEY = re.compile(r"\d{1,3}(?:[ \u00A0]?\d{3})*[.,]\d{2}")        # 1 234,56 | 1234.56
RE_DEC   = re.compile(r"^\d{1,6}[.,]\d{2}$")                          # 7,00 | 400,00

RE_HDR_ART = re.compile(r"(?i)artik|artikul")                         # Artikuls
RE_HDR_QTY = re.compile(r"(?i)daudz")                                 # Daudz.
RE_HDR_SUM = re.compile(r"(?i)summa|summ")                            # Summa

RE_ORDER_PATTERNS = [
    re.compile(r"(?:^|\s)#\s*(1\d{5})(?:\s|$)"),
    re.compile(r"(?i)\border[_\-\s]*0*(1\d{5})"),
    re.compile(r"(?<![\d.,])(1\d{5})(?![\d.,])"),
]

def to_float(tok: str) -> float:
    return float(tok.replace(" ", "").replace("\u00A0", "").replace(",", "."))

def to_int(tok: str) -> int:
    return int(round(to_float(tok)))

def fmt_money(tok: Optional[str]) -> str:
    if not tok:
        return "0,00"
    t = tok.replace("\u00A0", " ").strip()
    if "." in t and "," not in t:
        try:
            return f"{to_float(t):.2f}".replace(".", ",")
        except Exception:
            return t
    return t

@dataclass
class Word:
    x0: float; y0: float; x1: float; y1: float; text: str

@dataclass
class Line:
    y: float
    words: List[Word]
    text: str

@dataclass
class ColumnBand:
    name: str; x_left: float; x_right: float

@dataclass
class OrderMarker:
    x: float; y: float; value: str

# ------------ PDF helpers -------------
def load_page_words(pdf_bytes: bytes) -> List[List[Word]]:
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    out: List[List[Word]] = []
    for p in doc:
        raw = p.get_text("words")
        ws = [Word(w[0], w[1], w[2], w[3], w[4]) for w in raw]
        ws.sort(key=lambda w: (round(w.y0, 1), w.x0))
        out.append(ws)
    return out

def group_into_lines(words: List[Word]) -> List[Line]:
    if not words:
        return []
    heights = [w.y1 - w.y0 for w in words if (w.y1 - w.y0) > 0.2]
    h_med = statistics.median(heights) if heights else 8.0
    y_tol = max(1.2, h_med * Y_LINE_TOL_FACTOR)

    lines: List[List[Word]] = []
    cur: List[Word] = []
    last_y = None
    for w in words:
        if last_y is None or abs(w.y0 - last_y) <= y_tol:
            cur.append(w); last_y = w.y0 if last_y is None else (last_y + w.y0)/2
        else:
            cur.sort(key=lambda t: t.x0)
            lines.append(cur)
            cur = [w]; last_y = w.y0
    if cur:
        cur.sort(key=lambda t: t.x0)
        lines.append(cur)

    out: List[Line] = []
    for ln in lines:
        y_c = statistics.fmean([w.y0 for w in ln])
        text = " ".join(w.text for w in ln)
        out.append(Line(y=y_c, words=ln, text=text))
    out.sort(key=lambda L: L.y)
    return out

def detect_header_bands(lines: List[Line]) -> Optional[List[ColumnBand]]:
    for L in lines[:80]:
        t = L.text
        if RE_HDR_ART.search(t) and RE_HDR_QTY.search(t) and RE_HDR_SUM.search(t):
            def center(pattern):
                xs = [(w.x0+w.x1)/2 for w in L.words if pattern.search(w.text)]
                return sum(xs)/len(xs) if xs else None
            cx_art = center(RE_HDR_ART); cx_qty = center(RE_HDR_QTY); cx_sum = center(RE_HDR_SUM)
            centers = [(n,c) for n,c in [("Artikuls",cx_art),("Daudz.",cx_qty),("Summa",cx_sum)] if c is not None]
            if len(centers) < 2:
                continue
            centers.sort(key=lambda t: t[1])
            bands: List[ColumnBand] = []
            for i,(n,cx) in enumerate(centers):
                left  = (centers[i-1][1]+cx)/2 if i>0 else cx-90
                right = (cx+centers[i+1][1])/2 if i < len(centers)-1 else cx+180
                bands.append(ColumnBand(n, left, right))
            # –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏–º–µ–Ω–∞
            for b, nm in zip(sorted(bands, key=lambda b:b.x_left), ["Artikuls","Daudz.","Summa"]):
                b.name = nm
            return bands
    return None

def rough_bands(words: List[Word]) -> List[ColumnBand]:
    if not words:
        return [ColumnBand("Artikuls",0,200), ColumnBand("Daudz.",200,400), ColumnBand("Summa",400,800)]
    x_min = min(w.x0 for w in words); x_max = max(w.x1 for w in words)
    W = x_max - x_min
    return [
        ColumnBand("Artikuls", x_min-10, x_min+0.47*W),
        ColumnBand("Daudz.",   x_min+0.47*W, x_min+0.66*W),
        ColumnBand("Summa",    x_min+0.66*W, x_max+20)
    ]

def in_band(word: Word, band: ColumnBand) -> bool:
    cx = (word.x0+word.x1)/2
    return band.x_left <= cx <= band.x_right

# ------------ Order detection -------------
def extract_order_from_text(text: str) -> Optional[str]:
    for pat in RE_ORDER_PATTERNS:
        m = pat.search(text)
        if m:
            return m.group(1)
    return None

def detect_order_markers_from_lines(lines: List[Line]) -> List[OrderMarker]:
    markers: List[OrderMarker] = []
    for L in lines:
        val = extract_order_from_text(L.text)
        if val:
            xs = [(w.x0+w.x1)/2 for w in L.words if any(p.search(w.text) for p in RE_ORDER_PATTERNS)]
            cx = statistics.median(xs) if xs else (sum(w.x0 for w in L.words)/len(L.words))
            markers.append(OrderMarker(cx, L.y, val))
    if not markers:
        return []
    # –∫–æ–ª–æ–Ω–∫–∞ –ø–æ –º–µ–¥–∏–∞–Ω–µ X
    x_med = statistics.median([m.x for m in markers])
    col = [m for m in markers if abs(m.x - x_med) <= ORDER_X_TOL]
    if len(col) >= max(3, len(markers)//2):
        markers = col
    markers.sort(key=lambda m: m.y)
    return markers

def build_order_segments(markers: List[OrderMarker], top_y: float, bottom_y: float):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç [(y_start, y_end, value)] –ø–æ–∫—Ä—ã–≤–∞—é—â–∏–µ –≤—Å—é —Å—Ç—Ä–∞–Ω–∏—Ü—É."""
    if not markers:
        return [(top_y-1e9, bottom_y+1e9, "")]
    segs = []
    for i, m in enumerate(markers):
        y_start = markers[i-1].y if i>0 else top_y-1e9
        y_end   = markers[i+1].y if i+1<len(markers) else bottom_y+1e9
        # –¥–ª—è –±–æ–ª–µ–µ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ–≥–æ –¥–µ–ª–µ–Ω–∏—è ‚Äî —Å–µ—Ä–µ–¥–∏–Ω—ã –º–µ–∂–¥—É –º–µ—Ç–∫–∞–º–∏
        if i>0:
            y_start = (markers[i-1].y + m.y)/2
        if i+1<len(markers):
            y_end = (m.y + markers[i+1].y)/2
        segs.append((y_start, y_end, m.value))
    # –∫—Ä–∞—è
    first = markers[0]; last = markers[-1]
    segs.insert(0, (top_y-1e9, (first.y + (markers[1].y if len(markers)>1 else first.y+200))/2, first.value))
    segs.append(((last.y + (markers[-2].y if len(markers)>1 else last.y-200))/2, bottom_y+1e9, last.value))
    # —Å–ª–∏—Ç—å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è –∏ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å
    segs.sort(key=lambda s:s[0])
    merged = []
    for s in segs:
        if not merged or s[0] > merged[-1][1]:
            merged.append(list(s))
        else:
            merged[-1][1] = max(merged[-1][1], s[1])
            merged[-1][2] = s[2]
    return [(a,b,v) for a,b,v in merged]

def order_for_y(segments, y):
    for a,b,v in segments:
        if a <= y <= b:
            return v
    # fallback: –±–ª–∏–∂–∞–π—à–∞—è –ø–æ Y –º–µ—Ç–∫–∞
    nearest = min(segments, key=lambda s: min(abs(s[0]-y), abs(s[1]-y))) if segments else None
    return nearest[2] if nearest else ""

# ------------ –û—Å–Ω–æ–≤–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ -------------
def parse_pdf_to_df(pdf_bytes: bytes) -> pd.DataFrame:
    pages_words = load_page_words(pdf_bytes)
    rows = []

    for pw in pages_words:
        if not pw: 
            continue
        lines = group_into_lines(pw)
        top_y   = min(w.y0 for w in pw)
        bottom_y= max(w.y1 for w in pw)

        bands = detect_header_bands(lines)
        if not bands:
            bands = rough_bands(pw)
        band_map = {b.name: b for b in bands}

        # –∫–æ–ª–æ–Ω–∫–∞ –∑–∞–∫–∞–∑–æ–≤ -> —Å–µ–≥–º–µ–Ω—Ç—ã
        markers = detect_order_markers_from_lines(lines)
        segments = build_order_segments(markers, top_y, bottom_y)

        # —Å–æ–±—Ä–∞—Ç—å —Å–ø–∏—Å–æ–∫ –∏–Ω–¥–µ–∫—Å–æ–≤ ¬´—è–∫–æ—Ä–Ω—ã—Ö¬ª —Å—Ç—Ä–æ–∫ (–≥–¥–µ MPN)
        mpn_idxs: List[int] = []
        for i, L in enumerate(lines):
            if RE_MPN.search(L.text):
                mpn_idxs.append(i)

        for idx, i in enumerate(mpn_idxs):
            # –≥—Ä–∞–Ω–∏—Ü—ã –±–ª–æ–∫–∞ –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ MPN
            i_end = mpn_idxs[idx+1]-1 if idx+1<len(mpn_idxs) else len(lines)-1
            L = lines[i]
            m = RE_MPN.search(L.text)
            if not m:
                continue
            mpn = m.group(1)
            y_line = L.y

            # ORDER –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º
            order = order_for_y(segments, y_line)

            # QTY ‚Äî –ø–æ–∏—Å–∫ –≤ –∫–æ–ª–æ–Ω–∫–µ Daudz. –Ω–∞ –±–ª–∏–∂–∞–π—à–µ–π —Å—Ç—Ä–æ–∫–µ
            qty_val = None
            search_range = [i]
            for d in range(1, QTY_MAX_LOOK_LINES+1):
                if i-d >= 0: search_range.append(i-d)
                if i+d < len(lines): search_range.append(i+d)
            best = (1e9, None)
            for j in search_range:
                for w in lines[j].words:
                    if in_band(w, band_map["Daudz."]) and RE_DEC.match(w.text):
                        dy = abs(lines[j].y - y_line)
                        if dy < best[0]:
                            best = (dy, w.text)
            if best[1]:
                try: qty_val = to_int(best[1])
                except Exception: qty_val = 0
            else:
                qty_val = 0

            # TOTAL ‚Äî —Å—É–º–º–∞ –∏–∑ Summa, –±–ª–∏–∂–∞–π—à–∞—è –ø–æ Y –∏ –ø—Ä–∞–≤–µ–µ –≤—Å–µ—Ö –≤ —Å–≤–æ–µ–π —Å—Ç—Ä–æ–∫–µ
            total_tok = None
            best = (1e9, -1e9, None)  # (|dy|, x, tok)
            search_range = [i]
            for d in range(1, SUM_MAX_LOOK_LINES+1):
                if i-d >= 0: search_range.append(i-d)
                if i+d < len(lines): search_range.append(i+d)
            for j in search_range:
                money_words = [w for w in lines[j].words if in_band(w, band_map["Summa"]) and RE_MONEY.fullmatch(w.text)]
                for w in money_words:
                    dy = abs(lines[j].y - y_line)
                    xr = max(w.x0, w.x1)
                    cand = (dy, -xr, w.text)  # –ø—Ä–∞–≤–µ–µ ‚Üí xr –±–æ–ª—å—à–µ, –Ω–æ –º—ã –±–µ—Ä—ë–º min(), –ø–æ—ç—Ç–æ–º—É -xr
                    if cand < best:
                        best = cand
            total_tok = best[2]
            total_str = fmt_money(total_tok)

            # –µ—Å–ª–∏ total == qty –ø–æ –∑–Ω–∞—á–µ–Ω–∏—é (400,00 ‚Üî 400) –∏ –µ—Å—Ç—å –≤ —Å—Ç—Ä–æ–∫–µ –µ—â—ë –¥–µ–Ω—å–≥–∏ ‚Äî –≤–æ–∑—å–º–∏ —Å–ª–µ–¥—É—é—â–∏–π –ø—Ä–∞–≤–µ–µ
            if total_tok:
                try:
                    if abs(to_int(total_tok) - qty_val) == 0:
                        # –ø–æ–ø—Ä–æ–±—É–π –Ω–∞–π—Ç–∏ –≤—Ç–æ—Ä—É—é —Å–ø—Ä–∞–≤–∞ —Å—É–º–º—É
                        money_words = [w for w in L.words if in_band(w, band_map["Summa"]) and RE_MONEY.fullmatch(w.text)]
                        money_words.sort(key=lambda w: max(w.x0,w.x1))
                        if len(money_words) >= 2:
                            total_str = fmt_money(money_words[-1].text)
                except Exception:
                    pass

            rows.append({
                "MPN": mpn,
                "Replacem": "",
                "Quantity": qty_val,
                "Totalsprice": total_str,
                "Order reference": order
            })

    if not rows:
        return pd.DataFrame(columns=["MPN","Replacem","Quantity","Totalsprice","Order reference"])

    df = pd.DataFrame(rows).drop_duplicates(keep="last")
    df = df[["MPN","Replacem","Quantity","Totalsprice","Order reference"]]
    # –Ω–µ —Å–æ—Ä—Ç–∏—Ä—É—é, —á—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å –ø–æ—Ä—è–¥–æ–∫ ‚Äî –µ—Å–ª–∏ –Ω–∞–¥–æ: df.sort_values(["Order reference","MPN"], inplace=True)
    df.reset_index(drop=True, inplace=True)
    return df

# ------------ UI -------------
pdf_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç—å PDF-—Å—á—ë—Ç", type=["pdf"])
tpl_file = st.file_uploader("–®–∞–±–ª–æ–Ω Excel (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)", type=["xlsx"])

if pdf_file:
    data = pdf_file.read()
    df = parse_pdf_to_df(data)
    st.subheader("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä")
    st.dataframe(df, use_container_width=True)

    if st.button("–°–∫–∞—á–∞—Ç—å Excel"):
        if tpl_file:
            wb = load_workbook(tpl_file); ws = wb.active
        else:
            wb = Workbook(); ws = wb.active
            ws.append(["MPN","Replacem","Quantity","Totalsprice","Order reference"])
        for r in df.itertuples(index=False):
            ws.append(list(r))
        bio = io.BytesIO(); wb.save(bio)
        st.download_button(
            "–°–∫–∞—á–∞—Ç—å waybill.xlsx",
            data=bio.getvalue(),
            file_name="waybill.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
else:
    st.info("–õ–æ–≥–∏–∫–∞: –∫–æ–ª–æ–Ω–∫–∞ –∑–∞–∫–∞–∑–æ–≤ ‚Üí —Å–µ–≥–º–µ–Ω—Ç—ã –ø–æ Y; MPN=8***********; Qty –∏–∑ Daudz., Total –∏–∑ Summa (–ø–æ –±–ª–∏–∂–∞–π—à–µ–º—É Y).")
